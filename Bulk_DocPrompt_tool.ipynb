{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7od4N4HqhN1"
      },
      "source": [
        "* Click on 'Files' on the side menu and upload input.csv with the links inserted in column A.\n",
        "* To avoid errors, try not to have more than 50-60 links in the input file.\n",
        "* If you have more links, you can run the code multiple times by updating the input.csv file each time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2rsytyKhzpL"
      },
      "source": [
        "**This is the only block of code you would have to make changes (depending on the use case) in:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBja4zcBWD4M"
      },
      "outputs": [],
      "source": [
        "#To modify the prompt, change the content within the quotation marks in the value of the prompt variable below.\n",
        "prompt = \"\"\"\n",
        "Go through the document and share with me the following in JSON format (This is important. I want to avoid errors later when I try to parse the output):\n",
        "      1. Language\n",
        "      2. Summary in a paragraph with five sentences. While writing the summary, please assume that I already know about the Spotlight initiative. Do not define it for me again.\n",
        "      3. Target Stakeholders (For this, use one of more of following: 'General audience', 'Policymakers', 'Funders', 'CSOs', 'Communities', 'Private Sector', 'Coalitions', 'Spotlight teams', 'Service providers (e.g., care centers)', 'Multilateral/ bilateral organizations', 'Others'). Please know that service providers here would also include law enforcement/ police/ courts etc.\n",
        "      4. Target Geography (choose a country or a region that includes multiple countries like South East Asia. If it is not restricted to a single region, 'Global' will be the correct option). Do not provide an explanation.\n",
        "      5. Name of the Funder (Name of organizations like UNDP, UNFPA etc.). Do not provide any explanation. Leave blank if 'Funder' is not known or not applicable. Also, spotlight initiative is funded by the EU. If the funder is Spotlight, write Spotlight (and not EU)\n",
        "      6. Research Organizations (Specify the name of the organizations like Spotlight, UNDP etc.). Do not provide any explanation. Leave blank if 'Funder' is not known or not applicable.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRr9qFYh1IK"
      },
      "source": [
        "**Do not make any changes in the sections below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NZRgJrB814U"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai # Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6OCSs0UCTk"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7UkFF1H9YVJ"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import fitz\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "\n",
        "from google.api_core.exceptions import TooManyRequests\n",
        "from urllib.parse import urlparse\n",
        "from google.colab import userdata\n",
        "# Import the API key from config.py\n",
        "from config import GOOGLE_API_KEY\n",
        "\n",
        "# Configure genai with the imported API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcOWVDNM05IO"
      },
      "outputs": [],
      "source": [
        "def download_pdf(url, filename):\n",
        "    response = requests.get(url)\n",
        "    with open(filename, 'wb') as file:\n",
        "        file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8ATwk76UW25"
      },
      "outputs": [],
      "source": [
        "def pdf_to_text(pdf_file):\n",
        "    try:\n",
        "        # Open the provided PDF file\n",
        "        document = fitz.open(pdf_file)\n",
        "\n",
        "        # Initialize an empty string to store the text\n",
        "        text = \"\"\n",
        "\n",
        "        # Iterate through each page in the document\n",
        "        for page_num in range(len(document)):\n",
        "            page = document.load_page(page_num)\n",
        "            text += page.get_text()\n",
        "\n",
        "        # Close the document\n",
        "        document.close()\n",
        "        return text\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{pdf_file}' not found.\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An unexpected error occurred: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5xTW3SXQIfj"
      },
      "outputs": [],
      "source": [
        "def extract_file_id(url):\n",
        "    # Regular expression to match the file ID in the Google Docs URL\n",
        "    match = re.search(r'/d/([a-zA-Z0-9_-]+)', url)\n",
        "    # If a match is found, return the file ID\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rP-15sCQvS9"
      },
      "outputs": [],
      "source": [
        "def obtainfromDocs(file_id):\n",
        "  url = f'https://docs.google.com/document/d/{file_id}/export?format=txt'\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for non-200 status codes\n",
        "    return response.text\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    # Handle any request exceptions (including 400 errors)\n",
        "    print(f'Error downloading from Docs: {e}')\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99mWLbPDLVYs"
      },
      "outputs": [],
      "source": [
        "def obtainfromDrive(drive_link, save_path):\n",
        "    try:\n",
        "            # Extracting file ID from Google Drive link\n",
        "            file_id = drive_link.split(\"/\")[-2]\n",
        "\n",
        "            # Constructing direct download link for the file\n",
        "            download_link = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "            # Sending a GET request to the direct download link\n",
        "            response = requests.get(download_link)\n",
        "\n",
        "            # Saving the PDF file\n",
        "            with open(save_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            print(f\"Downloaded {drive_link} to {save_path}\")\n",
        "            pdf_path = save_path\n",
        "\n",
        "            text = pdf_to_text(pdf_path)\n",
        "\n",
        "            return text\n",
        "    except Exception as e:\n",
        "            print(f\"Failed to download {drive_link}: {str(e)}\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v982vKpHEkKf"
      },
      "outputs": [],
      "source": [
        "def obtainfromWebpage(url):\n",
        "    try:\n",
        "\n",
        "        # Remove leading BOM character if present\n",
        "        if url.startswith('\\ufeff'):\n",
        "            url = url[1:]\n",
        "\n",
        "        # Parse the URL and check if it has a scheme\n",
        "        parsed_url = urlparse(url)\n",
        "        if not parsed_url.scheme:\n",
        "\n",
        "            # Prepend https:// as a default scheme if missing\n",
        "            url = 'https://' + url\n",
        "\n",
        "        if '.pdf' in url:\n",
        "            # Call the function to download pdf\n",
        "            download_pdf(url,'temppdf.pdf')\n",
        "\n",
        "            # Write content to pdf file\n",
        "            filename = 'temppdf.pdf'\n",
        "\n",
        "            print(f\"File '{filename}' downloaded successfully\")\n",
        "\n",
        "            pdf_path = filename\n",
        "\n",
        "            text = pdf_to_text(pdf_path)\n",
        "            return text\n",
        "\n",
        "\n",
        "\n",
        "        if 'docs.google' in url:\n",
        "            # Call the function to handle Google Docs links\n",
        "            file_id = extract_file_id(url)\n",
        "            text = obtainfromDocs(file_id)\n",
        "            return text\n",
        "\n",
        "        # Requests URL and get response object\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Parse text obtained\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the first PDF link on the webpage\n",
        "        link = soup.find('a', href=lambda href: href and href.endswith('.pdf'))\n",
        "\n",
        "        if link:\n",
        "            pdf_url = link.get('href')\n",
        "            print(f\"Downloading file: {pdf_url}\")\n",
        "\n",
        "            # Handle relative URLs\n",
        "            if not pdf_url.startswith('http'):\n",
        "                pdf_url = url + pdf_url\n",
        "\n",
        "            # Get response object for PDF link\n",
        "            response_pdf = requests.get(pdf_url)\n",
        "\n",
        "            # Check if the request was successful\n",
        "            if response_pdf.status_code == 200:\n",
        "                # Extract filename from URL\n",
        "                filename = 'temppdf.pdf'\n",
        "\n",
        "                # Write content to pdf file\n",
        "                with open(filename, 'wb') as pdf_file:\n",
        "                    pdf_file.write(response_pdf.content)\n",
        "\n",
        "                print(f\"File '{filename}' downloaded successfully\")\n",
        "                pdf_path = filename\n",
        "                text = pdf_to_text(pdf_path)\n",
        "                return text\n",
        "\n",
        "            else:\n",
        "                text = obtainfromDrive(url,'temppdf.pdf')\n",
        "                return text\n",
        "        else:\n",
        "            text = obtainfromDrive(url,'temppdf.pdf')\n",
        "            return text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T9Bhj9GntRE"
      },
      "outputs": [],
      "source": [
        "def datatoCSV(newtext):\n",
        "\n",
        "    # Assuming the input_string is obtained from the response object\n",
        "    # Extract the relevant portion as a string\n",
        "    input_string = newtext\n",
        "\n",
        "    # Check if the string starts with a valid JSON opening character\n",
        "    if input_string.startswith('{'):\n",
        "        # Convert the string to a JSON object\n",
        "        json_object = json.loads(input_string)\n",
        "\n",
        "        # Prepare a dictionary to hold flattened values\n",
        "        flattened_data = {}\n",
        "\n",
        "        # Flatten the JSON object\n",
        "        for key, value in json_object.items():\n",
        "            if isinstance(value, list):\n",
        "                flattened_data[key] = ', '.join(value)\n",
        "            else:\n",
        "                flattened_data[key] = value\n",
        "\n",
        "        # Define the path to your existing CSV file\n",
        "        existing_csv_file = 'output.csv'\n",
        "\n",
        "        # Append the flattened data to the existing CSV file\n",
        "        with open(existing_csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "\n",
        "            # Check if the file is empty (i.e., no header present)\n",
        "            file.seek(0, 2)  # Move to the end of the file\n",
        "            file_empty = file.tell() == 0\n",
        "\n",
        "            # Write the header if the file is empty\n",
        "            if file_empty:\n",
        "                writer.writerow(flattened_data.keys())\n",
        "\n",
        "            # Write a single row of flattened data\n",
        "            writer.writerow(flattened_data.values())\n",
        "\n",
        "        print(\"Data has been successfully appended to\", existing_csv_file)\n",
        "    else:\n",
        "        print(\"Invalid JSON format. Skipping this entry.\")\n",
        "        with open('output.csv', 'a', newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow(['Error'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Epo66qaFq_8"
      },
      "outputs": [],
      "source": [
        "def append_to_csv(json_text, csv_filename):\n",
        "    try:\n",
        "\n",
        "        # Parse JSON text into a Python dictionary\n",
        "        data = json.loads(json_text)\n",
        "\n",
        "        # Extract keys from the first object to use as CSV header\n",
        "        fieldnames = list(data.keys())\n",
        "\n",
        "        # Check if the CSV file exists; if not, create it and write headers\n",
        "        file_exists = True\n",
        "        try:\n",
        "            with open(csv_filename, 'r') as f:\n",
        "                reader = csv.reader(f)\n",
        "                if not list(reader):  # Check if file is empty\n",
        "                    file_exists = False\n",
        "        except FileNotFoundError:\n",
        "            file_exists = False\n",
        "\n",
        "        with open(csv_filename, 'a', newline='') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "            if not file_exists:\n",
        "                writer.writeheader()  # Write headers only if file is empty\n",
        "\n",
        "            # Write the data as a new row in the CSV file\n",
        "            writer.writerow(data)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing JSON: {str(e)}\")\n",
        "        with open('output.csv', 'a', newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow(['Error(JSON Decoding Issue)'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRQUuGI7Awd-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.remove('output.csv')\n",
        "except FileNotFoundError:\n",
        "  print(\"Files not found, skipping deletion.\")\n",
        "except Exception as e:\n",
        "  print(f\"Error deleting files: {str(e)}\")\n",
        "with open('input.csv', mode='r') as input_file:\n",
        "    csv_reader = csv.reader(input_file)\n",
        "    # Iterate over each row in the input CSV\n",
        "    for row in csv_reader:\n",
        "        try:\n",
        "            os.remove('temppdf.pdf')\n",
        "            os.remove('temptext.txt')\n",
        "        except FileNotFoundError:\n",
        "            print(\"Files not found, skipping deletion.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting files: {str(e)}\")\n",
        "        # Assuming the URL is in the first column\n",
        "        fetch_url = row[0]\n",
        "\n",
        "        # Check if the fetch_url is '-'\n",
        "        if len(fetch_url)<5:\n",
        "            # Write 'Error' to the output CSV and continue to the next iteration\n",
        "            print(\"Error encountered\")\n",
        "            with open('output.csv', 'a', newline='') as csvfile:\n",
        "                    writer = csv.writer(csvfile)\n",
        "                    writer.writerow(['Error (because of -)'])\n",
        "            continue\n",
        "\n",
        "        # Download the PDF, convert to text\n",
        "        text=\"\"\n",
        "        text = obtainfromWebpage(fetch_url)\n",
        "\n",
        "        if text:\n",
        "                print(\"PDF converted to text successfully!\")\n",
        "\n",
        "                prompt = prompt + text\n",
        "\n",
        "                model = genai.GenerativeModel('gemini-1.5-flash', generation_config={\"response_mime_type\": \"application/json\", \"temperature\": 0.3})\n",
        "                try:\n",
        "                  response = model.generate_content(prompt)\n",
        "\n",
        "                except TooManyRequests:\n",
        "                  print(\"Rate limit exceeded. Retrying in 20 seconds...\")\n",
        "                  time.sleep(20)\n",
        "                  response = model.generate_content(prompt)\n",
        "\n",
        "                if response.candidates and response.candidates[0].content.parts:\n",
        "                    newtext = response.candidates[0].content.parts[0].text\n",
        "                    append_to_csv(newtext,\"output.csv\")\n",
        "                else:\n",
        "                    with open('output.csv', 'a', newline='') as csvfile:\n",
        "                          writer = csv.writer(csvfile)\n",
        "                          writer.writerow(['Error (because of no content parts)'])\n",
        "\n",
        "        else:\n",
        "                with open('output.csv', 'a', newline='') as csvfile:\n",
        "                    writer = csv.writer(csvfile)\n",
        "                    writer.writerow(['Error (text file empty)'])\n",
        "                print(\"Failed to convert PDF to text.\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
